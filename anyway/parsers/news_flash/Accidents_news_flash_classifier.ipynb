{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#import stanfordnlp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from hebtokenizer import tokenize\n",
    "import requests\n",
    "import string\n",
    "import time\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model('cc.he.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goldberg_old_tokenizer(sentence, keep_punc=False, first_sentence_only=False):\n",
    "    result=tokenize(sentence)\n",
    "    tokenized_words=[]\n",
    "    for word in result:\n",
    "        if first_sentence_only:\n",
    "            if word[1]=='.':\n",
    "                return tokenized_words\n",
    "        if not keep_punc:\n",
    "            if word[0]!='PUNCT':\n",
    "                tokenized_words.append(word[1])\n",
    "        else:\n",
    "            tokenized_words.append(word[1])\n",
    "    return tokenized_words\n",
    "\n",
    "def yap_tokenizer(sentence, keep_punc=False, first_sentence_only=False):\n",
    "    # Escape double quotes in JSON.\n",
    "    sentence= sentence.replace(r'\"', r'\\\"')\n",
    "    site_token='b17fe32045191775d07b19c05f990d16'\n",
    "    url = 'https://www.langndata.com/api/heb_parser?token={0}'.format(site_token)\n",
    "    _json='{\"data\":\"'+sentence+'\"}'\n",
    "    headers = {'content-type': 'application/json'}\n",
    "    r = requests.post(url,  data=_json.encode('utf-8'), headers={'Content-type': 'application/json; charset=utf-8'})\n",
    "    result=r.json()['lemmas'].split()\n",
    "    tokenized_words=[]\n",
    "    for word in result:\n",
    "        if first_sentence_only:\n",
    "            if word=='.':\n",
    "                return tokenized_words\n",
    "        if not keep_punc:\n",
    "            if word not in string.punctuation:\n",
    "                tokenized_words.append(word)\n",
    "        else:\n",
    "            tokenized_words.append(word)\n",
    "    return tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=pd.read_pickle('hebrew_stopwords.pkl').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('news_flash_19_7_19.xlsx')\n",
    "#nlp = stanfordnlp.Pipeline(lang='he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=dataset.title.tolist()\n",
    "y=[1 if label else 0 for label in dataset.accident.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    X.append(str(sentence))\n",
    "\n",
    "# for sentence in tqdm(sentences):\n",
    "#     X.append(' '.join([word.text for word in nlp(str(sentence)).sentences[0].words if type(word)!=float and word.text!=None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a8fc528400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y).plot.hist(density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohens kappa score: 0.6644513368380526\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5)\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)),('model',RandomForestClassifier(random_state=42, n_estimators=400, max_depth=3, class_weight='balanced'))])\n",
    "pipeline = Pipeline([('tfidf',TfidfVectorizer()),('model',XGBClassifier(max_depth=5))])\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(tokenizer=goldberg_old_tokenizer)),('model',lgb.LGBMClassifier(max_depth=3))])\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)), ('svd',TruncatedSVD(n_components=300)),('model',CatBoostClassifier(random_state=42, verbose=0))])\n",
    "print('cohens kappa score: '+str(np.array(cross_val_score(pipeline, X, y, scoring=make_scorer(cohen_kappa_score), cv=sss)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importance=[100*x for x in pipeline.named_steps['model'].feature_importances_.tolist()]\n",
    "pipeline.fit(X,y)\n",
    "feature_importance=[x for x in pipeline.named_steps['model'].feature_importances_.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=pipeline.named_steps['tfidf'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ratings=pd.DataFrame({\"Names\":feature_names,\"Importance\":feature_importance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ratings=features_ratings.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>בתאונת</td>\n",
       "      <td>0.055049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12367</th>\n",
       "      <td>רכב</td>\n",
       "      <td>0.054429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>בתאונה</td>\n",
       "      <td>0.052956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>מפגיעת</td>\n",
       "      <td>0.046305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>משאית</td>\n",
       "      <td>0.044162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12205</th>\n",
       "      <td>קשה</td>\n",
       "      <td>0.039734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>התאונה</td>\n",
       "      <td>0.039532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414</th>\n",
       "      <td>תאונה</td>\n",
       "      <td>0.039154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13416</th>\n",
       "      <td>תאונת</td>\n",
       "      <td>0.038498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>ברכב</td>\n",
       "      <td>0.036485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>הרכב</td>\n",
       "      <td>0.030437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12291</th>\n",
       "      <td>רוכב</td>\n",
       "      <td>0.029333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12261</th>\n",
       "      <td>רגל</td>\n",
       "      <td>0.028150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>נקבע</td>\n",
       "      <td>0.025120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>הנהג</td>\n",
       "      <td>0.022708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11272</th>\n",
       "      <td>עבודה</td>\n",
       "      <td>0.021065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>חפץ</td>\n",
       "      <td>0.018817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>אוטובוס</td>\n",
       "      <td>0.015821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>אנוש</td>\n",
       "      <td>0.015240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12544</th>\n",
       "      <td>שבע</td>\n",
       "      <td>0.013801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>באשקלון</td>\n",
       "      <td>0.013538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>נפצעה</td>\n",
       "      <td>0.013220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>נפצעו</td>\n",
       "      <td>0.013182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>דרכים</td>\n",
       "      <td>0.012876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10850</th>\n",
       "      <td>נפגעים</td>\n",
       "      <td>0.012774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>פועל</td>\n",
       "      <td>0.012545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>הולך</td>\n",
       "      <td>0.012534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>נפצע</td>\n",
       "      <td>0.012065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>באזור</td>\n",
       "      <td>0.011590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>באורח</td>\n",
       "      <td>0.011487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>הפסקת</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>הפעוט</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>הפעולה</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>הפלסטיני</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>הפלילי</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>הפליל</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>הפיצויים</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>הפטור</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>הפטרוכימית</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>הפיגוע</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>הפיגועים</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>הפיזור</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>הפיכה</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>הפיל</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>הפילה</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>הפיליפינים</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>הפיץ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>הפיצוץ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>הפלייאוף</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>הפיצוצים</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>הפיקוח</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4613</th>\n",
       "      <td>הפירמידות</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614</th>\n",
       "      <td>הפך</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>הפכו</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>הפלגים</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>הפלדה</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>הפלה</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>הפלות</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>הפליטים</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>תתקים</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Names  Importance\n",
       "2482       בתאונת    0.055049\n",
       "12367         רכב    0.054429\n",
       "2480       בתאונה    0.052956\n",
       "10008      מפגיעת    0.046305\n",
       "10238       משאית    0.044162\n",
       "12205         קשה    0.039734\n",
       "5129       התאונה    0.039532\n",
       "13414       תאונה    0.039154\n",
       "13416       תאונת    0.038498\n",
       "2339         ברכב    0.036485\n",
       "4934         הרכב    0.030437\n",
       "12291        רוכב    0.029333\n",
       "12261         רגל    0.028150\n",
       "10913        נקבע    0.025120\n",
       "4290         הנהג    0.022708\n",
       "11272       עבודה    0.021065\n",
       "6374          חפץ    0.018817\n",
       "254       אוטובוס    0.015821\n",
       "588          אנוש    0.015240\n",
       "12544         שבע    0.013801\n",
       "885       באשקלון    0.013538\n",
       "10882       נפצעה    0.013220\n",
       "10883       נפצעו    0.013182\n",
       "2872        דרכים    0.012876\n",
       "10850      נפגעים    0.012774\n",
       "11608        פועל    0.012545\n",
       "3441         הולך    0.012534\n",
       "10881        נפצע    0.012065\n",
       "799         באזור    0.011590\n",
       "793         באורח    0.011487\n",
       "...           ...         ...\n",
       "4645        הפסקת    0.000000\n",
       "4646        הפעוט    0.000000\n",
       "4647       הפעולה    0.000000\n",
       "4624     הפלסטיני    0.000000\n",
       "4623       הפלילי    0.000000\n",
       "4622        הפליל    0.000000\n",
       "4609     הפיצויים    0.000000\n",
       "4599        הפטור    0.000000\n",
       "4600   הפטרוכימית    0.000000\n",
       "4601       הפיגוע    0.000000\n",
       "4602     הפיגועים    0.000000\n",
       "4603       הפיזור    0.000000\n",
       "4604        הפיכה    0.000000\n",
       "4605         הפיל    0.000000\n",
       "4606        הפילה    0.000000\n",
       "4607   הפיליפינים    0.000000\n",
       "4608         הפיץ    0.000000\n",
       "4610       הפיצוץ    0.000000\n",
       "4621     הפלייאוף    0.000000\n",
       "4611     הפיצוצים    0.000000\n",
       "4612       הפיקוח    0.000000\n",
       "4613    הפירמידות    0.000000\n",
       "4614          הפך    0.000000\n",
       "4615         הפכו    0.000000\n",
       "4616       הפלגים    0.000000\n",
       "4617        הפלדה    0.000000\n",
       "4618         הפלה    0.000000\n",
       "4619        הפלות    0.000000\n",
       "4620      הפליטים    0.000000\n",
       "13797       תתקים    0.000000\n",
       "\n",
       "[13798 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yap_tokenized_sentences=[]\n",
    "# for i, sentence in enumerate(sentences):\n",
    "#     yap_tokenized_sentences.append(yap_tokenizer(sentence))\n",
    "yap_tokenized_sentences=pd.read_pickle('yap_tokenized_sentences.pkl').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for sentence in yap_tokenized_sentences:\n",
    "    X.append(str(' '.join(sentence)))\n",
    "\n",
    "# for sentence in tqdm(sentences):\n",
    "#     X.append(' '.join([word.text for word in nlp(str(sentence)).sentences[0].words if type(word)!=float and word.text!=None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohens kappa score: 0.728275538465518\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=10)\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)),('model',RandomForestClassifier(random_state=42, n_estimators=400, max_depth=3, class_weight='balanced'))])\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)),('model',XGBClassifier(random_state=42))])\n",
    "pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)),('model',lgb.LGBMClassifier(reg_lambda=1,max_depth=3,is_unbalance=True,random_state=42))])\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)), ('svd',TruncatedSVD(n_components=300)),('model',CatBoostClassifier(random_state=42, verbose=0))])\n",
    "print('cohens kappa score: '+str(np.array(cross_val_score(pipeline, X, y, scoring=make_scorer(cohen_kappa_score), cv=skf)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importance=[100*x for x in pipeline.named_steps['model'].feature_importances_.tolist()]\n",
    "pipeline.fit(X,y)\n",
    "feature_importance=[x for x in pipeline.named_steps['model'].feature_importances_.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=pipeline.named_steps['tfidf'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ratings=pd.DataFrame({\"Names\":feature_names,\"Importance\":feature_importance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ratings=features_ratings.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>תאונה</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>נפצע</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>פגיעה</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>נפגע</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>רכב</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>קשה</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>בן</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>נהג</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>ישראלי</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>שריפה</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>סמוך</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>כביש</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>ירי</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>גבר</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>שני</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>נהרג</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>אוטובוס</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>לאחר</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>בת</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>חשד</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>מוות</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>פצוע</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>נמוך</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>נמאס</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>נמל</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>נמצא</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>נמלט</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>נמנע</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>נמש</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>התראה</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>התרחק</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>התרסק</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>התפטר</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>התפוצץ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>התלונן</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>התנצל</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>התלקחות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>התמודד</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>התמודדות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>התמוטט</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>התנגד</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>התנגדות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>התנגש</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>התנגשות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>התנהלות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>התנחלות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>התנצלות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>התערבות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>התנקשות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>התנתק</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>התסיס</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>התעורר</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>התעלה</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>התעלל</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>התעללות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>התעמלות</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>התעקש</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>התערב</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>תשתית</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3361 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Names  Importance\n",
       "3248     תאונה          54\n",
       "2278      נפצע          51\n",
       "2601     פגיעה          43\n",
       "2266      נפגע          40\n",
       "3021       רכב          23\n",
       "2937       קשה          22\n",
       "479         בן          15\n",
       "2148       נהג          14\n",
       "1564    ישראלי          10\n",
       "3241     שריפה          10\n",
       "2433      סמוך           9\n",
       "1573      כביש           9\n",
       "1552       ירי           8\n",
       "556        גבר           7\n",
       "3214       שני           5\n",
       "2151      נהרג           4\n",
       "128    אוטובוס           3\n",
       "1652      לאחר           2\n",
       "545         בת           2\n",
       "1375       חשד           2\n",
       "1824      מוות           2\n",
       "2701      פצוע           1\n",
       "2237      נמוך           0\n",
       "2236      נמאס           0\n",
       "2238       נמל           0\n",
       "0           00           0\n",
       "2241      נמצא           0\n",
       "2239      נמלט           0\n",
       "2240      נמנע           0\n",
       "2242       נמש           0\n",
       "...        ...         ...\n",
       "1151     התראה           0\n",
       "1152     התרחק           0\n",
       "1153     התרסק           0\n",
       "1131     התפטר           0\n",
       "1129    התפוצץ           0\n",
       "1105    התלונן           0\n",
       "1116     התנצל           0\n",
       "1106   התלקחות           0\n",
       "1107    התמודד           0\n",
       "1108  התמודדות           0\n",
       "1109    התמוטט           0\n",
       "1110     התנגד           0\n",
       "1111   התנגדות           0\n",
       "1112     התנגש           0\n",
       "1113   התנגשות           0\n",
       "1114   התנהלות           0\n",
       "1115   התנחלות           0\n",
       "1117   התנצלות           0\n",
       "1128   התערבות           0\n",
       "1118   התנקשות           0\n",
       "1119     התנתק           0\n",
       "1120     התסיס           0\n",
       "1121    התעורר           0\n",
       "1122     התעלה           0\n",
       "1123     התעלל           0\n",
       "1124   התעללות           0\n",
       "1125   התעמלות           0\n",
       "1126     התעקש           0\n",
       "1127     התערב           0\n",
       "3360     תשתית           0\n",
       "\n",
       "[3361 rows x 2 columns]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "for sentence in sentences:\n",
    "    X.append(model.get_sentence_vector(' '.join(goldberg_old_tokenizer(sentence))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class SkMetrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.confusion = []\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "        self.f1s = []\n",
    "        self.kappa = []        \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        score = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        predict = np.round(np.asarray(self.model.predict(self.validation_data[0])))\n",
    "        targ = self.validation_data[1]\n",
    "        \n",
    "        self.confusion.append(confusion_matrix(targ, predict))\n",
    "        self.precision.append(precision_score(targ, predict))\n",
    "        self.recall.append(recall_score(targ, predict))\n",
    "        self.f1s.append(f1_score(targ, predict))\n",
    "        self.kappa.append(cohen_kappa_score(targ, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.metrics import cohen_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(y_true, y_pred):  \n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.metrics.auc(y_true, y_pred, num_thresholds=200, curve='ROC', summation_method='careful_interpolation' )\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\t\n",
    "    \"\"\"Precision metric.\t\n",
    "    Only computes a batch-wise average of precision. Computes the precision, a\n",
    "    metric for multi-label classification of how many selected items are\n",
    "    relevant.\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\t\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\t\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\t\n",
    "    \"\"\"Recall metric.\t\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\t\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\t\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Computes the F1 Score\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return (2 * p * r) / (p + r + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print('— val_f1: %f — val_precision: %f — val_recall %f'%(_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0720 11:36:22.212417  9420 deprecation_wrapper.py:119] From C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0720 11:36:22.218418  9420 deprecation_wrapper.py:119] From C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0720 11:36:22.226419  9420 deprecation_wrapper.py:119] From C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0720 11:36:22.287268  9420 deprecation_wrapper.py:119] From C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0720 11:36:22.414296  9420 deprecation_wrapper.py:119] From C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0720 11:36:22.427299  9420 deprecation_wrapper.py:119] From C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0720 11:36:22.430302  9420 deprecation.py:323] From C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "net=Sequential()\n",
    "net.add(Dense(128, activation='relu', input_shape=(300,)))\n",
    "net.add(BatchNormalization())\n",
    "net.add(Dense(64, activation='relu'))\n",
    "net.add(BatchNormalization())\n",
    "net.add(Dense(32, activation='relu'))\n",
    "net.add(BatchNormalization())\n",
    "net.add(Dense(1, activation='sigmoid'))\n",
    "net.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(np.array(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5130 samples, validate on 1711 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.4975 - val_loss: 0.2850\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.1711 - val_loss: 0.1111\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0668 - val_loss: 0.0641\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0426 - val_loss: 0.0565\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0310 - val_loss: 0.0545\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0280 - val_loss: 0.0530\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0191 - val_loss: 0.0482\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0131 - val_loss: 0.0523\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0138 - val_loss: 0.0493\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0137 - val_loss: 0.0531\n"
     ]
    }
   ],
   "source": [
    "history=net.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "# plt.plot(history.history[net.metrics_names[1]])\n",
    "# plt.plot(history.history['val_'+net.metrics_names[1]])\n",
    "# plt.title('model '+net.metrics_names[1])\n",
    "# plt.ylabel(net.metrics_names[1])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history[net.metrics_names[0]])\n",
    "plt.plot(history.history['val_'+net.metrics_names[0]])\n",
    "plt.title('model '+net.metrics_names[0])\n",
    "plt.ylabel(net.metrics_names[0])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keras_model():\n",
    "    net=Sequential()\n",
    "    net.add(Dense(128, activation='relu', input_shape=(300,)))\n",
    "    net.add(BatchNormalization())\n",
    "    net.add(Dense(64, activation='relu'))\n",
    "    net.add(BatchNormalization())\n",
    "    net.add(Dense(32, activation='relu'))\n",
    "    net.add(BatchNormalization())\n",
    "    net.add(Dense(1, activation='sigmoid'))\n",
    "    net.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 4s - loss: 0.4586\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1221\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0572\n",
      "Epoch 1/3\n",
      " - 4s - loss: 0.4468\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1194\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0566\n",
      "Epoch 1/3\n",
      " - 4s - loss: 0.4469\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1216\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0542\n",
      "Epoch 1/3\n",
      " - 4s - loss: 0.4417\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1275\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0615\n",
      "Epoch 1/3\n",
      " - 5s - loss: 0.4452\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1247\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0580\n",
      "Epoch 1/3\n",
      " - 5s - loss: 0.4497\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1207\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0581\n",
      "Epoch 1/3\n",
      " - 5s - loss: 0.4396\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1243\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0612\n",
      "Epoch 1/3\n",
      " - 5s - loss: 0.4557\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1252\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0586\n",
      "Epoch 1/3\n",
      " - 5s - loss: 0.4273\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1159\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0554\n",
      "Epoch 1/3\n",
      " - 5s - loss: 0.4507\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.1233\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0569\n",
      "cohens kappa score: 0.6746685869313607\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=10)\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)),('model',RandomForestClassifier(random_state=42, n_estimators=400, max_depth=3, class_weight='balanced'))])\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)),('model',XGBClassifier(random_state=42))])\n",
    "pipeline = Pipeline([('model',KerasClassifier(make_keras_model, epochs=3, verbose=2))])\n",
    "#pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words=stopwords)), ('svd',TruncatedSVD(n_components=300)),('model',CatBoostClassifier(random_state=42, verbose=0))])\n",
    "print('cohens kappa score: '+str(np.array(cross_val_score(pipeline, X, y, scoring=make_scorer(cohen_kappa_score), cv=sss)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_dataset=dataset[['accident','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inplace_change(filename, old_string, new_string):\n",
    "    with open(filename,encoding=\"utf8\") as f:\n",
    "        newText=f.read().replace(old_string, new_string)\n",
    "    with open(filename, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(newText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Iterable, List, Optional, Set, Tuple\n",
    "import math\n",
    "\n",
    "Vector = List[float]\n",
    "\n",
    "def most_similar(base_vector: Vector, words: List[Word]) -> List[Tuple[float, Word]]:\n",
    "    \"\"\"Finds n words with smallest cosine similarity to a given word\"\"\"\n",
    "    words_with_distance = [(cosine_similarity_normalized(base_vector, w.vector), w) for w in words]\n",
    "    # We want cosine similarity to be as large as possible (close to 1)\n",
    "    sorted_by_distance = sorted(words_with_distance, key=lambda t: t[0], reverse=True)\n",
    "    return sorted_by_distance\n",
    "\n",
    "def print_most_similar(words: List[Word], text: str) -> None:\n",
    "    base_word = find_word(text, words)\n",
    "    if not base_word:\n",
    "        print(f\"Uknown word: {text}\")\n",
    "        return\n",
    "    print(f\"Words related to {base_word.text}:\")\n",
    "    sorted_by_distance = [\n",
    "        word.text for (dist, word) in\n",
    "            most_similar(base_word.vector, words)\n",
    "            if word.text.lower() != base_word.text.lower()\n",
    "        ]\n",
    "    print(', '.join(sorted_by_distance[:10]))\n",
    "\n",
    "def read_word() -> str:\n",
    "    return input(\"Type a word: \")\n",
    "\n",
    "def find_word(text: str, words: List[Word]) -> Optional[Word]:\n",
    "#     try:\n",
    "#         return next(w for w in words if text == w.text)\n",
    "#     except StopIteration:\n",
    "#         return None\n",
    "    return words[text]\n",
    "\n",
    "def closest_analogies(\n",
    "    left2: str, left1: str, right2: str, words: List[Word]\n",
    ") -> List[Tuple[float, Word]]:\n",
    "    word_left1 = find_word(left1, words)\n",
    "    word_left2 = find_word(left2, words)\n",
    "    word_right2 = find_word(right2, words)\n",
    "#     if (not word_left1) or (not word_left2) or (not word_right2):\n",
    "#         return []\n",
    "    vector = add(\n",
    "        sub(word_left1, word_left2),\n",
    "        word_right2)\n",
    "    closest = most_similar(vector, words)[:10]\n",
    "    def is_redundant(word: str) -> bool:\n",
    "        \"\"\"\n",
    "        Sometimes the two left vectors are so close the answer is e.g.\n",
    "        \"shirt-clothing is like phone-phones\". Skip 'phones' and get the next\n",
    "        suggestion, which might be more interesting.\n",
    "        \"\"\"\n",
    "        word_lower = word.lower()\n",
    "        return (\n",
    "            left1.lower() in word_lower or\n",
    "            left2.lower() in word_lower or\n",
    "            right2.lower() in word_lower)\n",
    "    closest_filtered = [(dist, w) for (dist, w) in closest if not is_redundant(w.text)]\n",
    "    return closest_filtered\n",
    "\n",
    "def print_analogy(left2: str, left1: str, right2: str, words: List[Word]) -> None:\n",
    "    analogies = closest_analogies(left2, left1, right2, words)\n",
    "    if (len(analogies) == 0):\n",
    "        print(f\"{left2}-{left1} is like {right2}-?\")\n",
    "    else:\n",
    "        (dist, w) = analogies[0]\n",
    "        #alternatives = ', '.join([f\"{w.text} ({dist})\" for (dist, w) in analogies])\n",
    "        print(f\"{left2}-{left1} is like {right2}-{w.text}\")\n",
    "\n",
    "def l2_len(v: Vector) -> float:\n",
    "    return math.sqrt(sum([x*x for x in v]))\n",
    "\n",
    "def dot(v1: Vector, v2: Vector) -> float:\n",
    "    assert len(v1) == len(v2)\n",
    "    return sum([x*y for (x,y) in zip(v1, v2)])\n",
    "\n",
    "def add(v1: Vector, v2: Vector) -> Vector:\n",
    "    assert len(v1) == len(v2)\n",
    "    return [x + y for (x,y) in zip(v1, v2)]\n",
    "\n",
    "def sub(v1: Vector, v2: Vector) -> Vector:\n",
    "    assert len(v1) == len(v2)\n",
    "    return [x - y for (x,y) in zip(v1, v2)]\n",
    "\n",
    "def normalize(v: Vector) -> Vector:\n",
    "    l = l2_len(v)\n",
    "    return [x / l for x in v]\n",
    "\n",
    "def cosine_similarity_normalized(v1: Vector, v2: Vector) -> float:\n",
    "    \"\"\"\n",
    "    Returns the cosine of the angle between the two vectors.\n",
    "    Each of the vectors must have length (L2-norm) equal to 1.\n",
    "    Results range from -1 (very different) to 1 (very similar).\n",
    "    \"\"\"\n",
    "    return dot(v1, v2)\n",
    "\n",
    "\n",
    "class Word:\n",
    "    \"\"\"A single word (one line of the input file)\"\"\"\n",
    "\n",
    "    def __init__(self, text: str, vector: Vector, frequency: int) -> None:\n",
    "        self.text = text\n",
    "        self.vector = vector\n",
    "        self.frequency = frequency\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        vector_preview = ', '.join(map(str, self.vector[:2]))\n",
    "        return f\"{self.text} [{vector_preview}, ...]\"\n",
    "    \n",
    "from typing import Iterable, List, Set\n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import re\n",
    "\n",
    "def load_words(file_path: str) -> List[Word]:\n",
    "    \"\"\"Load and cleanup the data.\"\"\"\n",
    "    print(f\"Loading {file_path}...\")\n",
    "    words = load_words_raw(file_path)\n",
    "    print(f\"Loaded {len(words)} words.\")\n",
    "\n",
    "    #num_dimensions = most_common_dimension(words)\n",
    "    words = [w for w in words if len(w.vector) == 300]\n",
    "    #print(f\"Using {num_dimensions}-dimensional vectors, {len(words)} remain.\")\n",
    "\n",
    "    words = remove_stop_words(words)\n",
    "    print(f\"Removed stop words, {len(words)} remain.\")\n",
    "\n",
    "    words = remove_duplicates(words)\n",
    "    print(f\"Removed duplicates, {len(words)} remain.\")\n",
    "\n",
    "    return words\n",
    "\n",
    "def load_words_raw(file_path: str) -> List[Word]:\n",
    "    \"\"\"Load the file as-is, without doing any validation or cleanup.\"\"\"\n",
    "    def parse_line(line: str, frequency: int) -> Word:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        vector = normalize([float(x) for x in tokens[1:]])\n",
    "        return Word(word, vector, frequency)\n",
    "\n",
    "    words = []\n",
    "    # Words are sorted from the most common to the least common ones\n",
    "    frequency = 1\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            w = parse_line(line, frequency)\n",
    "            words.append(w)\n",
    "            frequency += 1\n",
    "    return words\n",
    "\n",
    "def iter_len(iter: Iterable[complex]) -> int:\n",
    "    return sum(1 for _ in iter)\n",
    "\n",
    "def most_common_dimension(words: List[Word]) -> int:\n",
    "    \"\"\"\n",
    "    There is a line in the input file which is missing a word\n",
    "    (search -0.0739, -0.135, 0.0584).\n",
    "    \"\"\"\n",
    "    lengths = sorted([len(word.vector) for word in words])\n",
    "    dimensions = [(k, iter_len(v)) for k, v in groupby(lengths)]\n",
    "    print(\"Dimensions:\")\n",
    "    for (dim, num_vectors) in dimensions:\n",
    "        print(f\"{num_vectors} {dim}-dimensional vectors\")\n",
    "    most_common = sorted(dimensions, key=lambda t: t[1], reverse=True)[0]\n",
    "    return most_common[0]\n",
    "\n",
    "# We want to ignore these characters,\n",
    "# so that e.g. \"U.S.\", \"U.S\", \"US_\" and \"US\" are the same word.\n",
    "ignore_char_regex = re.compile(\"[\\W_]\")\n",
    "\n",
    "# Has to start and end with an alphanumeric character\n",
    "is_valid_word = re.compile(\"^[^\\W_].*[^\\W_]$\")\n",
    "\n",
    "def remove_duplicates(words: List[Word]) -> List[Word]:\n",
    "    seen_words: Set[str] = set()\n",
    "    unique_words: List[Word] = []\n",
    "    for w in words:\n",
    "        canonical = ignore_char_regex.sub(\"\", w.text)\n",
    "        if not canonical in seen_words:\n",
    "            seen_words.add(canonical)\n",
    "            # Keep the original ordering\n",
    "            unique_words.append(w)\n",
    "    return unique_words\n",
    "\n",
    "def remove_stop_words(words: List[Word]) -> List[Word]:\n",
    "    return [w for w in words if (\n",
    "        len(w.text) > 1 and is_valid_word.match(w.text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cc.he.300.vec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-45-ccdf4e349410>\", line 1, in <module>\n",
      "    words = load_words('cc.he.300.vec')\n",
      "  File \"<ipython-input-44-b81786369115>\", line 119, in load_words\n",
      "    words = load_words_raw(file_path)\n",
      "  File \"<ipython-input-44-b81786369115>\", line 146, in load_words_raw\n",
      "    for line in f:\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 173, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\saske\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3324\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3325\u001b[1;33m                     \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3326\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-ccdf4e349410>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cc.he.300.vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-b81786369115>\u001b[0m in \u001b[0;36mload_words\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loading {file_path}...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_words_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loaded {len(words)} words.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-b81786369115>\u001b[0m in \u001b[0;36mload_words_raw\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3324\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3325\u001b[1;33m                     \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3326\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2038\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2039\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2040\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3340\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3341\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3342\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3343\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3344\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2040\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2041\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2042\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2044\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1385\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1286\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1288\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m             )\n\u001b[0;32m   1290\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m             \u001b[0mformatted_exceptions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m             \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "words = load_words('cc.he.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f54a142d9190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint_analogy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'מלך'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'מלכה'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'נסיך'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-8d772bf32dcc>\u001b[0m in \u001b[0;36mprint_analogy\u001b[1;34m(left2, left1, right2, words)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_analogy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWord\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0manalogies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosest_analogies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalogies\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{left2}-{left1} is like {right2}-?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-8d772bf32dcc>\u001b[0m in \u001b[0;36mclosest_analogies\u001b[1;34m(left2, left1, right2, words)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mword_left2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mword_right2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mword_left1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mword_left2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mword_right2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     vector = add(\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "print_analogy('מלך', 'מלכה' , 'נסיך', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t685\n",
      "P@1\t0.500\n",
      "R@1\t1.000\n",
      "N\t685\n",
      "P@1\t0.500\n",
      "R@1\t1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-2e53fe5ebabd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0minplace_change\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'news_flash_19_7_19_data_test.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0minplace_change\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'news_flash_19_7_19_data_test.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mfasttext_supervised\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_supervised\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'news_flash_19_7_19_data_train.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwordNgrams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfasttext_supervised\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'news_flash_19_7_19_data_test.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fasttext\\FastText.py\u001b[0m in \u001b[0;36mtrain_supervised\u001b[1;34m(*kargs, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[0mft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m     \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "\n",
    "for train_ind, test_ind in sss.split(fasttext_dataset['title'],fasttext_dataset['accident']):\n",
    "    fasttext_dataset_train=fasttext_dataset.loc[train_ind,:]\n",
    "    fasttext_dataset_train.loc[:,'title']=' __label__'+fasttext_dataset_train.loc[:,'accident'].astype(str)+' '+fasttext_dataset_train.loc[:,'title']\n",
    "    fasttext_dataset_train['title'].to_csv('news_flash_19_7_19_data_train.txt',index=False, header=False)\n",
    "    fasttext_dataset_test=fasttext_dataset.loc[test_ind,:]\n",
    "    fasttext_dataset_test.loc[:,'title']='__label__'+fasttext_dataset_test.loc[:,'accident'].astype(str)+' '+fasttext_dataset_test.loc[:,'title']\n",
    "    fasttext_dataset_test['title'].to_csv('news_flash_19_7_19_data_test.txt',index=False, header=False)\n",
    "    inplace_change('news_flash_19_7_19_data_train.txt','\\\"','')\n",
    "    inplace_change('news_flash_19_7_19_data_train.txt','\\'','')\n",
    "    inplace_change('news_flash_19_7_19_data_test.txt','\\\"','')\n",
    "    inplace_change('news_flash_19_7_19_data_test.txt','\\'','')\n",
    "    fasttext_supervised=fasttext.train_supervised('news_flash_19_7_19_data_train.txt', )\n",
    "    print_results(*fasttext_supervised.test('news_flash_19_7_19_data_test.txt', k=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__False', '__label__True'), array([9.99458015e-01, 5.62023022e-04]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_supervised.predict('תאונת דרכים עם נפצעים',k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__False', '__label__True']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_supervised.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "fasttext_dataset.loc[:,'title']=fasttext_dataset.loc[:,'title']+' __label__'+fasttext_dataset.loc[:,'accident'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_supervised=fasttext.train_supervised('news_flash_19_7_19_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ומורה', 0.7511934041976929), ('1.מורה', 0.6926032304763794), ('.מורה', 0.6877073049545288), ('2.מורה', 0.6840677261352539), ('המורה', 0.681587815284729), ('מורה-מחנך', 0.6695026755332947), ('כמורה', 0.6671140789985657), ('kמורה', 0.6603051424026489), ('למורה', 0.6582226753234863), ('ךמורה', 0.6465803384780884)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saske\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43108505\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import fasttext as ft\n",
    "\n",
    "model = ft.load_facebook_model('cc.he.300.bin')\n",
    "\n",
    "print(model.most_similar('מורה'))\n",
    "# Output = [('headteacher', 0.8075869083404541), ('schoolteacher', 0.7955552339553833), ('teachers', 0.733420729637146), ('teaches', 0.6839243173599243), ('meacher', 0.6825737357139587), ('teach', 0.6285147070884705), ('taught', 0.6244685649871826), ('teaching', 0.6199781894683838), ('schoolmaster', 0.6037642955780029), ('lessons', 0.5812176465988159)]\n",
    "\n",
    "print(model.similarity('מורה', 'ללמד'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('מלכהּ', 0.5259336233139038),\n",
       " ('ומלך', 0.49719732999801636),\n",
       " ('ומלכה', 0.48895424604415894),\n",
       " ('מלכהבן', 0.4842609763145447),\n",
       " ('מלכי', 0.47994059324264526),\n",
       " ('ומלכי', 0.4713260531425476),\n",
       " ('ממליך', 0.4627130627632141),\n",
       " ('למלך', 0.4592019319534302),\n",
       " ('מלכהלע', 0.454645037651062),\n",
       " ('המלך', 0.44962286949157715)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['מלך', 'מלכה'], negative=['אישה'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
